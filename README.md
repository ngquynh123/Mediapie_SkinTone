# ğŸ¨ Skin Tone Classification using MediaPipe & MobileNetV2

PhÃ¢n loáº¡i tÃ´ng mÃ u da (skin tone) tá»« áº£nh khuÃ´n máº·t sá»­ dá»¥ng MediaPipe Face Mesh vÃ  MobileNetV2.

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n nÃ y phÃ¢n loáº¡i tÃ´ng mÃ u da thÃ nh **6 loáº¡i** (Type_1 Ä‘áº¿n Type_6) dá»±a trÃªn:

- TrÃ­ch xuáº¥t vÃ¹ng da máº·t (mÃ¡ trÃ¡i, mÃ¡ pháº£i, cáº±m) báº±ng **MediaPipe Face Mesh**
- Loáº¡i bá» ná»n vÃ  vÃ¹ng máº¯t/miá»‡ng Ä‘á»ƒ chá»‰ giá»¯ láº¡i da
- PhÃ¢n tÃ­ch mÃ u sáº¯c trong khÃ´ng gian **LAB color space**
- Huáº¥n luyá»‡n model phÃ¢n loáº¡i báº±ng **MobileNetV2**

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
SKINTONE/
â”œâ”€â”€ pre_processing/          # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ extract_face_regions.py      # TrÃ­ch xuáº¥t vÃ¹ng mÃ¡ & cáº±m
â”‚   â”œâ”€â”€ extract_face_gray.py         # TrÃ­ch xuáº¥t khuÃ´n máº·t (ná»n xÃ¡m)
â”‚   â”œâ”€â”€ lab_cheek_chin_data.py       # Xá»­ lÃ½ dá»¯ liá»‡u LAB
â”‚   â”œâ”€â”€ skin_tone_labeler.py         # GÃ¡n nhÃ£n tÃ´ng mÃ u da
â”‚   â”œâ”€â”€ augment_Type1.py             # Data augmentation
â”‚   â””â”€â”€ LAB.py                       # PhÃ¢n tÃ­ch LAB color space
â”‚
â”œâ”€â”€ public/                  # Training & Inference
â”‚   â”œâ”€â”€ mobilenetV2.py               # Training script chÃ­nh
â”‚   â”œâ”€â”€ train_test_val.py            # Chia dá»¯ liá»‡u train/val/test
â”‚   â””â”€â”€ loc.py                       # Lá»c áº£nh theo LAB distance
â”‚
â”œâ”€â”€ mobilenetv2_best_*.pth   # Trained models (8 variants)
â””â”€â”€ .gitignore
```

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u

- Python 3.8+
- CUDA (náº¿u dÃ¹ng GPU)

### CÃ¡c thÆ° viá»‡n

```bash
pip install torch torchvision
pip install mediapipe opencv-python
pip install scikit-image albumentations
pip install numpy pandas matplotlib seaborn tqdm
```

## ğŸ“Š Quy trÃ¬nh

### 1ï¸âƒ£ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

#### TrÃ­ch xuáº¥t vÃ¹ng mÃ¡ & cáº±m

```bash
python pre_processing/extract_face_regions.py
```

- Sá»­ dá»¥ng MediaPipe Face Mesh phÃ¡t hiá»‡n 478 landmarks
- TrÃ­ch xuáº¥t 3 vÃ¹ng: **mÃ¡ trÃ¡i**, **mÃ¡ pháº£i**, **cáº±m**
- Loáº¡i bá» ná»n báº±ng Selfie Segmentation

#### TrÃ­ch xuáº¥t khuÃ´n máº·t vá»›i ná»n xÃ¡m

```bash
python pre_processing/extract_face_gray.py
```

- Giá»¯ láº¡i vÃ¹ng khuÃ´n máº·t
- Che vÃ¹ng máº¯t vÃ  miá»‡ng
- Thay ná»n báº±ng xÃ¡m (RGB 128,128,128)

#### PhÃ¢n tÃ­ch LAB & gÃ¡n nhÃ£n

```bash
python pre_processing/skin_tone_labeler.py
```

- Chuyá»ƒn Ä‘á»•i sang LAB color space
- TÃ­nh Î”E (Delta E) so vá»›i template
- GÃ¡n nhÃ£n Type_1 â†’ Type_6

### 2ï¸âƒ£ Huáº¥n luyá»‡n Model

```bash
python public/mobilenetV2.py
```

**Kiáº¿n trÃºc Model:**

- Base: MobileNetV2 (pretrained ImageNet)
- Custom classifier:
  ```
  Dropout(0.5) â†’ Linear(1280, 128) â†’ ReLU â†’ BatchNorm1d â†’ Linear(128, 6)
  ```

**Hyperparameters:**

- Image size: 224Ã—224
- Batch size: 32
- Epochs: 50
- Optimizer: AdamW (lr=1e-4, weight_decay=1e-2)
- Scheduler: ReduceLROnPlateau
- Loss: CrossEntropyLoss

**Data Augmentation:**

- HorizontalFlip
- ShiftScaleRotate
- RandomBrightnessContrast
- GaussNoise

### 3ï¸âƒ£ ÄÃ¡nh giÃ¡ & Inference

```python
# Load model
model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)
model.classifier = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(1280, 128),
    nn.ReLU(),
    nn.BatchNorm1d(128),
    nn.Linear(128, 6)
)
model.load_state_dict(torch.load("mobilenetv2_best_cheek_chin.pth"))
model.eval()

# Predict
# ... (xem code trong public/mobilenetV2.py)
```

## ğŸ“ Trained Models

Dá»± Ã¡n cung cáº¥p **8 model variants**:

| Model                                 | MÃ´ táº£                           |
| ------------------------------------- | ------------------------------- |
| `mobilenetv2_best.pth`                | Base model                      |
| `mobilenetv2_best_cheek_chin.pth`     | Train trÃªn vÃ¹ng mÃ¡ + cáº±m        |
| `mobilenetv2_best_skin.pth`           | Train trÃªn toÃ n bá»™ da máº·t       |
| `mobilenetv2_best_final.pth`          | Final optimized version         |
| `mobilenetv2_best_albu.pth`           | Vá»›i Albumentations augmentation |
| `mobilenetv2_best_f.pth`              | Fine-tuned variant              |
| `mobilenetv2_best_cheek.pth`          | Chá»‰ vÃ¹ng mÃ¡                     |
| `mobilenetv2_best_cheek_chin_new.pth` | Version má»›i nháº¥t                |

## ğŸ¯ PhÆ°Æ¡ng phÃ¡p phÃ¢n loáº¡i

### A. PhÃ¢n tÃ­ch LAB Color Space

- **L**: Lightness (Ä‘á»™ sÃ¡ng) â†’ phÃ¢n biá»‡t da sÃ¡ng/tá»‘i
- **a**: Green-Red axis â†’ mÃ u Ä‘á» trong da
- **b**: Blue-Yellow axis â†’ mÃ u vÃ ng trong da

### B. Delta E (Î”E)

Äo khoáº£ng cÃ¡ch mÃ u sáº¯c giá»¯a 2 máº«u:

```
Î”E = âˆš[(L1-L2)Â² + (a1-a2)Â² + (b1-b2)Â²]
```

- Î”E < 12: Gáº§n vá»›i tone template
- Î”E > 20: KhÃ¡c biá»‡t rÃµ rá»‡t

### C. Voting Mechanism

Dá»± Ä‘oÃ¡n tá»« 3 vÃ¹ng (mÃ¡ trÃ¡i, mÃ¡ pháº£i, cáº±m) â†’ chá»n káº¿t quáº£ phá»• biáº¿n nháº¥t

## ğŸ“ˆ Káº¿t quáº£

- Training accuracy: ~85-90%
- Validation accuracy: ~80-85%
- Test accuracy: ~75-80%

## ğŸ”§ TÃ¹y chá»‰nh

### Thay Ä‘á»•i sá»‘ lá»›p phÃ¢n loáº¡i

```python
num_classes = 4  # Thay 6 thÃ nh 4
model.classifier[-1] = nn.Linear(128, num_classes)
```

### Äiá»u chá»‰nh threshold LAB

```python
# Trong loc.py
THRESHOLD = 10  # Giáº£m Ä‘á»ƒ cháº·t cháº½ hÆ¡n
```

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh! Vui lÃ²ng:

1. Fork repo
2. Táº¡o branch má»›i (`git checkout -b feature/AmazingFeature`)
3. Commit thay Ä‘á»•i (`git commit -m 'Add some AmazingFeature'`)
4. Push lÃªn branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

## ğŸ“ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i MIT License.

## ğŸ“§ LiÃªn há»‡

- GitHub: [@ngquynh123](https://github.com/ngquynh123)
- Repository: [Mediapie_SkinTone](https://github.com/ngquynh123/Mediapie_SkinTone)

## ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev/) - Face Mesh & Selfie Segmentation
- [PyTorch](https://pytorch.org/) - Deep Learning framework
- [MobileNetV2](https://arxiv.org/abs/1801.04381) - Efficient CNN architecture
